{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edfb8ff",
   "metadata": {},
   "source": [
    "# Assignment 4 - Web Scraping Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a9e97",
   "metadata": {},
   "source": [
    "## Q1: Scrape Books from https://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ee1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "titles, prices, availability, ratings = [], [], [], []\n",
    "\n",
    "page = 1\n",
    "while True:\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    if not books:\n",
    "        break\n",
    "    \n",
    "    for book in books:\n",
    "        titles.append(book.h3.a[\"title\"])\n",
    "        prices.append(book.find(\"p\", class_=\"price_color\").text.strip())\n",
    "        availability.append(book.find(\"p\", class_=\"instock availability\").text.strip())\n",
    "        ratings.append(book.find(\"p\")[\"class\"][1])  # Star rating\n",
    "    \n",
    "    page += 1\n",
    "\n",
    "books_df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Price\": prices,\n",
    "    \"Availability\": availability,\n",
    "    \"Star Rating\": ratings\n",
    "})\n",
    "\n",
    "books_df.to_csv(\"books.csv\", index=False)\n",
    "books_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450002b",
   "metadata": {},
   "source": [
    "## Q2: Scrape IMDB Top 250 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/chart/top/\")\n",
    "time.sleep(3)\n",
    "\n",
    "movies, years, ranks, ratings = [], [], [], []\n",
    "\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list-summary-item\")\n",
    "for idx, row in enumerate(rows, start=1):\n",
    "    title_elem = row.find_element(By.CSS_SELECTOR, \"h3\")\n",
    "    title = title_elem.text.split('. ', 1)[-1]\n",
    "    movies.append(title)\n",
    "    years.append(row.find_element(By.CSS_SELECTOR, \".cli-title-metadata-item\").text)\n",
    "    ranks.append(idx)\n",
    "    ratings.append(row.find_element(By.CSS_SELECTOR, \".ipc-rating-star\").text.split()[0])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "imdb_df = pd.DataFrame({\n",
    "    \"Rank\": ranks,\n",
    "    \"Movie Title\": movies,\n",
    "    \"Year of Release\": years,\n",
    "    \"IMDB Rating\": ratings\n",
    "})\n",
    "\n",
    "imdb_df.to_csv(\"imdb_top250.csv\", index=False)\n",
    "imdb_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd594caa",
   "metadata": {},
   "source": [
    "## Q3: Scrape Weather Information from https://www.timeanddate.com/weather/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a251a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather_url = \"https://www.timeanddate.com/weather/\"\n",
    "response = requests.get(weather_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "cities, temps, conditions = [], [], []\n",
    "\n",
    "rows = soup.select(\"table tbody tr\")\n",
    "for row in rows:\n",
    "    city_elem = row.find(\"a\")\n",
    "    if city_elem:\n",
    "        cities.append(city_elem.text.strip())\n",
    "        temps.append(row.find_all(\"td\")[1].text.strip())\n",
    "        conditions.append(row.find_all(\"td\")[2].text.strip())\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    \"City Name\": cities,\n",
    "    \"Temperature\": temps,\n",
    "    \"Weather Condition\": conditions\n",
    "})\n",
    "\n",
    "weather_df.to_csv(\"weather.csv\", index=False)\n",
    "weather_df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
